# ===========================================
# NL Query Configuration
# ===========================================

# Database Configuration
DB_TYPE=postgres              # postgres or mysql
DB_NAME=your_database_name
DB_USER=your_username
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432                  # 5432 for postgres, 3306 for mysql

# ===========================================
# LLM Provider Configuration
# ===========================================
# Supported providers: openai, anthropic, ollama, vllm, openai-compatible

LLM_PROVIDER=openai           # Choose your provider

# --- OpenAI Configuration ---
# For: GPT-4, GPT-4o, GPT-3.5-turbo
OPENAI_API_KEY=sk-your-openai-api-key
# LLM_MODEL=gpt-4o            # Default: gpt-4o

# --- Anthropic (Claude) Configuration ---
# For: Claude 3.5 Sonnet, Claude 3 Opus, etc.
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
# LLM_MODEL=claude-sonnet-4-20250514

# --- Ollama Configuration (Local) ---
# For: Llama 3.1, Mistral, CodeLlama, etc.
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.1
# LLM_BASE_URL=http://localhost:11434

# --- vLLM Configuration ---
# For: Self-hosted models via vLLM
# LLM_PROVIDER=vllm
# LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
# LLM_BASE_URL=http://localhost:8000/v1

# --- OpenAI-Compatible Configuration ---
# For: LM Studio, LocalAI, Together AI, Groq, etc.
# LLM_PROVIDER=openai-compatible
# LLM_MODEL=your-model-name
# LLM_BASE_URL=http://localhost:1234/v1
# OPENAI_API_KEY=your-api-key-or-EMPTY

# ===========================================
# LLM Settings (Optional)
# ===========================================
LLM_MAX_TOKENS=500
LLM_TEMPERATURE=0.7

# ===========================================
# Other Settings (Optional)
# ===========================================
TIME_ZONE=UTC
ENABLE_SCHEMA_CACHE=true
ENABLE_QUERY_OPTIMIZATION=true
ENABLE_CHAT_HISTORY=true
RESULTS_PER_PAGE=10
MAX_RESULTS=1000
QUERY_TIMEOUT=30
